= Notes certification course
:toc: left
:imagesdir: ../documentation/images/

----
# Get complete cluster info
kubectl cluster-info
----

.base attribute for k8s yaml files
[source,yaml]
----
apiVersion:
kind:
metadata:
spec:
----

.apiVersion values
|===
|Kind |Version

|Pod
|v1

|Service
|v1

|ReplicaSet
|apps/v1

|Deployment
|apps/v1

|===

== Pods

.typical definition base for pod
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
  labels:
    app: myapp
spec:
  containers:
    - name: nginx
      image: nginx
----

.Extract a definition into a yaml file
----
kubectl get pod <pod-name> -o yaml > pod-definition.yaml
----

.An alternative is to edit directly
----
kubectl edit pod <pod-name>
----

== ReplicaSet

.typical definition for replicaset
[source,yaml]
----
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: myapp-replicaset
  labels:
    app: myapp
spec:
  replicas: 1
  template:
    metadata:
      name: aName
      labels:
        app: myapp
    spec:
      containers:
        - name: nginx
          image: nginx
  selector:
    matchLabels:
      app: myapp
----

.example of how labels are used in replicaset (to monitor already created pods)
image::labels.png[]

.Updating the replica set (is this the same as apply?)
----
kubectl replace -f <filename>.yml

# or

# Note that this does not update the acutal file, it will keep it's value of 1 in replicas attribute
kubectl scale --replicas=4 -f <filename>.yml
# or using type and label
kubectl scale --replicas=3 deployment -l app=webapp
----

== Deployments

image::deployment.png[]

.typical definition for deployment
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
  labels:
    app: myapp
spec:
  replicas: 1
  template:
    metadata:
      name: aName
      labels:
        app: myapp
    spec:
      containers:
        - name: nginx
          image: nginx
  selector:
    matchLabels:
      app: myapp
----

== Imperative commands

Generate POD Manifest YAML file (-o yaml). Don't create it(--dry-run=client)::
+
----
#deprecated with generator
kubectl run --generator=run-pod/v1 redis --image=redis:alpine --dry-run=client -o yaml

kubectl run redis --image=redis:alpine --dry-run=client -o yaml
----

Generate Deployment YAML file (-o yaml). Don't create it(--dry-run=client)::
+
----
kubectl create deployment --image=nginx nginx --dry-run=client -o yaml
----

[IMPORTANT]
kubectl create deployment does not have a --replicas option. You could first create it and then scale it using the kubectl scale command

Save it to a file - (If you need to modify or add some other details)::
+
----
kubectl create deployment --image=nginx nginx --dry-run=client -o yaml > nginx-deployment.yaml
----

Create a Service named redis-service of type ClusterIP to expose pod redis on port 6379::
+
----
kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml

# or

kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml
----

Create a Service named nginx of type NodePort to expose pod nginx's port 80 on port 30080 on the nodes::
+
----
kubectl expose pod nginx --port=80 --name nginx-service --dry-run=client -o yaml

#(This will automatically use the pod's labels as selectors, but you cannot specify the node port. You have to generate a definition file and then add the node port in manually before creating the service with the pod.)

# or

kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml
----

Different output types::

* `-o json` Output a JSON formatted API object.

* `-o name` Print only the resource name and nothing else.

* `-o wide` Output in the plain-text format with any additional information.

* `-o yaml` Output a YAML formatted API object.

Reference: https://kubernetes.io/docs/reference/kubectl/conventions/

https://kubernetes.io/docs/reference/kubectl/overview/

https://kubernetes.io/docs/reference/kubectl/cheatsheet/

== Namespace

.get/create in another namespace than default
[source,bash]
----
kubectl get pods --namespace=kube-system

kubectl create --namespace=kube-system -f <file>.yml
----

It is also possible to define namespace in defintion file:

[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
  namespace: kube-system
  labels:
    app: myapp
spec:
  containers:
    - name: nginx
      image: nginx
----

.example specifying new namespace
[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  name: dev
----

Then run create as usual with -f option

or the imperative way

----
kubectl create namespace dev
----

Switch between namespaces::
+
----
kubectl config set-context $(kubectl config current-context) --namespace=dev
----

View in all namespaces::
+
----
kubectl get pods --all-namespaces
----

.resource quota
[source,yaml]
----
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: dev
spec:
  hard:
    pods: "10"
    request.cpu: "4"
    request.memory: 5Gi
    limits.cpu: "10"
    limits.memory: 10Gi

----

.example of dns name when referring to service in other namespace
----
db-service.dev.svc.cluster.local
----

== Configuration

.mapping between docker command and k8s
image::docker-cmd-mapping.png[]

[NOTE]
====
Remember, you CANNOT edit specifications of an existing POD other than the below.

* spec.containers[*].image
* spec.initContainers[*].image
* spec.activeDeadlineSeconds
* spec.tolerations

So if you want to change the command or args for a running pod, you must delete and recreate it.

Examples:

. `kubectl edit pod <pod name>` (will be saved in tmp dir)
. `kubectl delete pod <pod_name>`
. `kubectl create -f <path_to_saved_tmp_file>`

Another way:

. `kubectl get pod webapp -o yaml > my-new-pod.yaml`
. `vi my-new-pod.yaml`
. `kubectl delete pod <pod_name>>`
. `kubectl create -f my-new-pod.yaml`

====

=== ConfigMaps

----
# imperative way
kubectl create configmap appconfig --from-literal=APP_COLOR=blue
kubectl create configmap appconfig --from-file=app_config.properties

# declarative way
kubectl create -f <yaml>
----

.ConfigMap declaration yaml file
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: appconfig
data:
  APP_COLOR: blue
  APP_MODE: production
----

----
kubectl get configmaps

kubectl describe configmaps
----

.example of using all properties of a configMap in a pod definition
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
  namespace: kube-system
  labels:
    app: myapp
spec:
  containers:
    - name: nginx
      image: nginx
      envFrom:
        - configMapRef:
            name: appconfig
----

.example of using a single property of a configMap in a pod definition
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
  namespace: kube-system
  labels:
    app: myapp
spec:
  containers:
    - name: nginx
      image: nginx
      env:
        - name: APP_COLOR
          valueFrom:
            configMapKeyRef:
              name: appconfig
              key: APP_COLOR
----

=== Secrets

----
# imperative way
kubectl create secret generic appsecret --from-literal=DB_HOST=mysql \
                                        --from-literal=DB_PASS=passw0rd

kubectl create secret generic appsecret --from-file=app_config.properties

# declarative way
kubectl create -f <yaml>
----

.Secret declaration yaml file
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: appsecret
data:
  DB_HOST: mysql
  DB_PASS: passw0rd
----

[IMPORTANT]
====
The key/values in a secret declarative definition file must be encoded!

`echo -n 'mysql' | base64`

`echo -n 'passw0rd' | base64`

[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: appsecret
data:
  DB_HOST: bXlzcWw=
  DB_PASS: cGFzc3cwcmQ=
----

A value can be decoded back using
`echo -n 'cGFzc3cwcmQ=' | base64 --decode`
====

----
kubectl get secrets

kubectl describe secrets

# To view the values as well
kubectl get secret appsecret -o yaml
----

.example of using all properties of a Secret in a pod definition
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
  namespace: kube-system
  labels:
    app: myapp
spec:
  containers:
    - name: nginx
      image: nginx
      envFrom:
        - secretRef:
            name: appsecret
----

.example of using a single property of a Secret in a pod definition
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
  namespace: kube-system
  labels:
    app: myapp
spec:
  containers:
    - name: nginx
      image: nginx
      env:
        - name: DB_PASS
          valueFrom:
            secretKeyRef:
              name: appsecret
              key: DB_PASS
----

[NOTE]
====
Remember that secrets encode data in base64 format. Anyone with the base64 encoded secret can easily decode it. As such the secrets can be considered as not very safe.

The concept of safety of the Secrets is a bit confusing in Kubernetes. The https://kubernetes.io/docs/concepts/configuration/secret[kubernetes documentation page] and a lot of blogs out there refer to secrets as a "safer option" to store sensitive data. They are safer than storing in plain text as they reduce the risk of accidentally exposing passwords and other sensitive data. In my opinion it's not the secret itself that is safe, it is the practices around it.

Secrets are not encrypted, so it is not safer in that sense. However, some best practices around using secrets make it safer. As in best practices like:

* Not checking-in secret object definition files to source code repositories.

* https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/[Enabling Encryption at Rest] for Secrets so they are stored encrypted in ETCD.

Also the way kubernetes handles secrets. Such as:

* A secret is only sent to a node if a pod on that node requires it.

* Kubelet stores the secret into a tmpfs so that the secret is not written to disk storage.

* Once the Pod that depends on the secret is deleted, kubelet will delete its local copy of the secret data as well.

Read about the https://kubernetes.io/docs/concepts/configuration/secret/#protections[protections] and https://kubernetes.io/docs/concepts/configuration/secret/#risks[risks] of using secrets https://kubernetes.io/docs/concepts/configuration/secret/#risks[here]

Having said that, there are other better ways of handling sensitive data like passwords in Kubernetes, such as using tools like Helm Secrets, https://www.vaultproject.io/[HashiCorp Vault].

====

=== Security context

How to set docker security related configs, such as user to run, or adding/removing linux capabilites such as MAC_ADMIN.

.example setting user id for all containers running in pod (pod level)
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
  labels:
    app: myapp
spec:
  securityContext:
    runAsUser: 1000
  containers:
    - name: nginx
      image: nginx
----

.example setting user id and adding a capability for a container (container level)
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
  labels:
    app: myapp
spec:
  containers:
    - name: nginx
      image: nginx
      securityContext:
        runAsUser: 1000
        capabilities:
          add: ["MAC_ADMIN"]
----

[NOTE]
Declaring capabilities is only possible at container level

----
# Finding out the user running a container
kubectl exec ubuntu-sleeper whoami

# Setting the data
kubectl exec ubuntu-sleeper -- date -s '19 APR 2012 11:14:00'
----

=== Service accounts

Service accounts are used by applications for interacting with K8s (apis etc). Typically apps: Prometheus (for accessing metric), GitLab/Jenkins (for deploying applications).

----
kubectl create serviceaccount <name>

kubectl get serviceaccount

# A token is autmatically created and stored as a secret, use `kubectl describe` to see the name of token
kubectl describe serviceaccount <name>

# To see the secret
kubectl describe secret <token_name>
----

The token can be used an authorization Bearer token in calls to api.

When the application using the token is deployed in the same K8s-cluster, then there is no need to export tokens. Instead the token is provided to a pod by mounting it as a _volume_.

In k8s, every namespace has a default service account created. This gets mounted by default in all pods running in namespace. See "mounts" when doing `kubectl describe pod xxx`.

[IMPORTANT]
The default namespace service account is very restricted, it can only run very basic api queries.

It is possible to define the pod to use other service accounts:

[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
spec:
  containers:
    - name: nginx
      image: nginx
  serviceAccountName: my-account-name
  # If you want to disable auto-mounting of default service tokens
  automountServiceAccountToken: false
----

=== Resource requirements

image::resources.png[]

image::resource-limiting.png[]

image::resource-notes.png[]

=== Taints and toleration

Taints and tolerations are used to restrict which pods that can be scheduled on a node.

* Taints are set on nodes

* Tolerations are set on pods

Syntax for setting taint::
kubectl taint nodes <node-name> key=value:<taint-effect>
+
There are three taint-effects: NoSchedule, PreferNoSchedule, NoExecute
+
----
kubectl taint nodes node1 app=blue:NoSchedule
----

Tolerations are added in definition::
+
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
spec:
  containers:
    - name: nginx
      image: nginx
  tolerations:
    - key: "app"
      operator: "Equal"
      value: "blue"
      effect: "NoSchedule"
----

----
# Example of untainting a node
kubectl taint nodes master node-role.kubernetes.io/master:NoSchedule-
----

Taint will only make sure that a certain node will accept a certain type of pods. But these pods may end up in other nodes as well. If the requirement is to run a type of pod on a specific node only, use concept <<Node affinity>>.

=== Node selectors

Sometimes we want to run "heavy" applications on nodes that are large enough to handle it. This assumes that we may have a cluster with large nodes, and some smaller nodes. We can then label the large nodes and make sure that the pod ends up there.

[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
spec:
  containers:
    - name: nginx
      image: nginx
  nodeSelector:
    size: Large
----

Syntax for labelling: `kubectl label nodes <node-name> <label-key>=<label-value>`

----
kubectl label nodes node01 size=Large
----

Using node selectors has its limitations. We cannot specify things like "run on Large or Medium" or "run only on NOT Small". For this, see <<Node affinity>>

=== Node affinity

.This does exactly the same as in the node selectors example
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
spec:
  containers:
    - name: nginx
      image: nginx
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: size
                operator: In
                values:
                  - Large
----

.example of "run on Large and Medium"
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
spec:
  containers:
    - name: nginx
      image: nginx
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: size
                operator: In
                values:
                  - Large
                  - Medium
----

.example of "run on not Small"
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: aName
spec:
  containers:
    - name: nginx
      image: nginx
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: size
                operator: NotIn
                values:
                  - Small
----

About affinity types:

* requiredDuringSchedulingIgnoredDuringExecution: This states that the scheduler should match the affinity rules, and if no node could be found, it does not deploy the pod. Already existing pods (when the affinity is set) is ignored and continues to run.

* preferredDuringSchedulingIgnoredDuringExecution: States that if the scheduler cannot find a node that applies to the rules, then just run it on any node.

====
Make sure you check out these tips and tricks from other students who have cleared the exam:

https://www.linkedin.com/pulse/my-ckad-exam-experience-atharva-chauthaiwale/

https://medium.com/@harioverhere/ckad-certified-kubernetes-application-developer-my-journey-3afb0901014

https://github.com/lucassha/CKAD-resources
====

== Multi-container pods

There are three types of multi-container pods:

* sidecar

* adapter

* ambassador


